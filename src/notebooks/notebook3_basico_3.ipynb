{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ” Notebook 3: Parsear Tags e Extrair Dados\n",
    "\n",
    "**Objetivo**: Usar XML parser para extrair dados estruturados das notÃ­cias\n",
    "\n",
    "**O que vamos fazer:**\n",
    "1. ğŸ› ï¸ Configurar parser XML profissional\n",
    "2. ğŸ” Parsear o RSS e extrair elementos\n",
    "3. ğŸ“‹ Estruturar dados de cada notÃ­cia\n",
    "4. ğŸ§¹ Limpar e formatar informaÃ§Ãµes\n",
    "5. ğŸ“Š Analisar dados extraÃ­dos\n",
    "6. ğŸ’¾ Preparar dados para o CSV\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§¹ 5. Limpeza e FormataÃ§Ã£o dos Dados\n",
    "\n",
    "Vamos limpar e formatar os dados extraÃ­dos para melhor qualidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpar_dados_noticias(dados_brutos):\n",
    "    \"\"\"\n",
    "    Limpa e formata os dados extraÃ­dos\n",
    "    \"\"\"\n    print(\"ğŸ§¹ Iniciando limpeza e formataÃ§Ã£o dos dados...\")\n    \n    dados_limpos = []\n    \n    for i, item in enumerate(dados_brutos, 1):\n        print(f\"   ğŸ”§ Limpando item {i}/{len(dados_brutos)}\", end=\"\\r\")\n        \n        item_limpo = item.copy()\n        \n        # Limpar tÃ­tulo\n        if item_limpo['titulo']:\n            item_limpo['titulo'] = html.unescape(item_limpo['titulo'])\n            item_limpo['titulo'] = re.sub(r'\\s+', ' ', item_limpo['titulo']).strip()\n        \n        # Limpar descriÃ§Ã£o\n        if item_limpo['descricao']:\n            # Remover tags HTML da descriÃ§Ã£o\n            item_limpo['descricao'] = re.sub(r'<[^>]+>', '', item_limpo['descricao'])\n            item_limpo['descricao'] = html.unescape(item_limpo['descricao'])\n            item_limpo['descricao'] = re.sub(r'\\s+', ' ', item_limpo['descricao']).strip()\n        \n        # Formatar data\n        if item_limpo['data_publicacao']:\n            item_limpo['data_formatada'] = formatar_data_rss(item_limpo['data_publicacao'])\n        else:\n            item_limpo['data_formatada'] = None\n        \n        # Validar URL\n        if item_limpo['link']:\n            item_limpo['link_valido'] = item_limpo['link'].startswith(('http://', 'https://'))\n        else:\n            item_limpo['link_valido'] = False\n        \n        # Calcular estatÃ­sticas do item\n        item_limpo['tamanho_titulo'] = len(item_limpo['titulo']) if item_limpo['titulo'] else 0\n        item_limpo['tamanho_descricao'] = len(item_limpo['descricao']) if item_limpo['descricao'] else 0\n        \n        dados_limpos.append(item_limpo)\n    \n    print(f\"\\nâœ… Limpeza concluÃ­da! {len(dados_limpos)} items processados\")\n    return dados_limpos\n\ndef formatar_data_rss(data_rss):\n    \"\"\"\n    Converte data RSS para formato brasileiro\n    \"\"\"\n    try:\n        # Formato tÃ­pico: \"Wed, 08 Aug 2025 10:30:00 -0300\"\n        # Remover timezone para simplificar parsing\n        data_sem_tz = data_rss.rsplit(' ', 1)[0]\n        \n        # Tentar diferentes formatos\n        formatos = [\n            \"%a, %d %b %Y %H:%M:%S\",\n            \"%d %b %Y %H:%M:%S\",\n            \"%Y-%m-%d %H:%M:%S\"\n        ]\n        \n        for formato in formatos:\n            try:\n                data_obj = datetime.strptime(data_sem_tz, formato)\n                return data_obj.strftime(\"%d/%m/%Y %H:%M:%S\")\n            except ValueError:\n                continue\n        \n        # Se nÃ£o conseguiu converter, retorna original\n        return data_rss\n        \n    except Exception:\n        return data_rss\n\n# Executar limpeza\nif dados_noticias:\n    dados_limpos = limpar_dados_noticias(dados_noticias)\nelse:\n    dados_limpos = []\n    print(\"âš ï¸ Nenhum dado para limpar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š 6. AnÃ¡lise dos Dados ExtraÃ­dos\n",
    "\n",
    "Vamos analisar os dados extraÃ­dos e gerar estatÃ­sticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisar_dados_extraidos(dados):\n",
    "    \"\"\"\n",
    "    Analisa os dados extraÃ­dos e gera estatÃ­sticas\n",
    "    \"\"\"\n    if not dados:\n        print(\"âŒ Nenhum dado para analisar\")\n        return None\n    \n    print(\"ğŸ“Š ANÃLISE DOS DADOS EXTRAÃDOS\")\n    print(\"=\" * 40)\n    \n    total_items = len(dados)\n    \n    # EstatÃ­sticas bÃ¡sicas\n    print(f\"ğŸ“ˆ ESTATÃSTICAS BÃSICAS:\")\n    print(f\"   Total de notÃ­cias: {total_items}\")\n    \n    # Completude dos dados\n    campos_principais = ['titulo', 'link', 'descricao', 'data_publicacao', 'categoria']\n    \n    print(f\"\\nâœ… COMPLETUDE DOS DADOS:\")\n    for campo in campos_principais:\n        count_validos = sum(1 for item in dados if item.get(campo))\n        percentual = (count_validos / total_items) * 100\n        print(f\"   {campo.capitalize()}: {count_validos}/{total_items} ({percentual:.1f}%)\")\n    \n    # AnÃ¡lise de categorias\n    categorias = {}\n    for item in dados:\n        cat = item.get('categoria', 'Sem categoria')\n        if cat:\n            categorias[cat] = categorias.get(cat, 0) + 1\n    \n    print(f\"\\nğŸ“‚ CATEGORIAS ENCONTRADAS ({len(categorias)} Ãºnicas):\")\n    for categoria, count in sorted(categorias.items(), key=lambda x: x[1], reverse=True)[:10]:\n        print(f\"   {categoria}: {count} notÃ­cias\")\n    \n    # AnÃ¡lise de tamanhos\n    tamanhos_titulo = [item['tamanho_titulo'] for item in dados if item.get('tamanho_titulo', 0) > 0]\n    tamanhos_descricao = [item['tamanho_descricao'] for item in dados if item.get('tamanho_descricao', 0) > 0]\n    \n    if tamanhos_titulo:\n        print(f\"\\nğŸ“ ANÃLISE DE TAMANHOS:\")\n        print(f\"   TÃ­tulo mÃ©dio: {sum(tamanhos_titulo) / len(tamanhos_titulo):.1f} caracteres\")\n        print(f\"   TÃ­tulo maior: {max(tamanhos_titulo)} caracteres\")\n        print(f\"   TÃ­tulo menor: {min(tamanhos_titulo)} caracteres\")\n    \n    if tamanhos_descricao:\n        print(f\"   DescriÃ§Ã£o mÃ©dia: {sum(tamanhos_descricao) / len(tamanhos_descricao):.1f} caracteres\")\n        print(f\"   DescriÃ§Ã£o maior: {max(tamanhos_descricao)} caracteres\")\n        print(f\"   DescriÃ§Ã£o menor: {min(tamanhos_descricao)} caracteres\")\n    \n    # Qualidade dos links\n    links_validos = sum(1 for item in dados if item.get('link_valido', False))\n    print(f\"\\nğŸ”— QUALIDADE DOS LINKS:\")\n    print(f\"   Links vÃ¡lidos: {links_validos}/{total_items} ({(links_validos/total_items)*100:.1f}%)\")\n    \n    return {\n        'total_items': total_items,\n        'categorias': categorias,\n        'completude': {campo: sum(1 for item in dados if item.get(campo)) for campo in campos_principais},\n        'links_validos': links_validos\n    }\n\n# Executar anÃ¡lise\nestats_dados = analisar_dados_extraidos(dados_limpos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‘€ 7. VisualizaÃ§Ã£o de Amostras\n",
    "\n",
    "Vamos visualizar algumas amostras dos dados extraÃ­dos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exibir_amostras_dados(dados, quantidade=3):\n",
    "    \"\"\"\n",
    "    Exibe amostras dos dados extraÃ­dos\n",
    "    \"\"\"\n    if not dados:\n        print(\"âŒ Nenhum dado para exibir\")\n        return\n    \n    print(f\"ğŸ‘€ AMOSTRAS DOS DADOS EXTRAÃDOS (primeiras {quantidade})\")\n    print(\"=\" * 60)\n    \n    for i, item in enumerate(dados[:quantidade], 1):\n        print(f\"\\nğŸ“° NOTÃCIA {i}:\")\n        print(\"-\" * 40)\n        \n        # InformaÃ§Ãµes principais\n        print(f\"ğŸ†” ID: {item.get('id_item', 'N/A')}\")\n        print(f\"ğŸ·ï¸ TÃ­tulo: {item.get('titulo', 'N/A')[:80]}{'...' if len(item.get('titulo', '')) > 80 else ''}\")\n        print(f\"ğŸ“… Data: {item.get('data_formatada', 'N/A')} (original: {item.get('data_publicacao', 'N/A')[:25]}...)\")\n        print(f\"ğŸ“‚ Categoria: {item.get('categoria', 'N/A')}\")\n        print(f\"ğŸ”— Link: {item.get('link', 'N/A')[:60]}{'...' if len(item.get('link', '')) > 60 else ''}\")\n        print(f\"ğŸ“ DescriÃ§Ã£o: {item.get('descricao', 'N/A')[:120]}{'...' if len(item.get('descricao', '')) > 120 else ''}\")\n        \n        # Metadados\n        print(f\"ğŸ“Š Metadados:\")\n        print(f\"   Tamanho tÃ­tulo: {item.get('tamanho_titulo', 0)} chars\")\n        print(f\"   Tamanho descriÃ§Ã£o: {item.get('tamanho_descricao', 0)} chars\")\n        print(f\"   Link vÃ¡lido: {'âœ…' if item.get('link_valido', False) else 'âŒ'}\")\n        print(f\"   Elementos XML: {item.get('total_elementos', 0)}\")\n        print(f\"   ExtraÃ­do em: {item.get('timestamp_extracao', 'N/A')}\")\n\n# Exibir amostras\nexibir_amostras_dados(dados_limpos, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ 8. PreparaÃ§Ã£o para CSV e Salvamento\n",
    "\n",
    "Vamos preparar os dados para serem salvos em CSV no prÃ³ximo notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_dados_para_csv(dados):\n",
    "    \"\"\"\n",
    "    Prepara os dados para serem salvos em CSV\n",
    "    Remove campos desnecessÃ¡rios e organiza campos principais\n",
    "    \"\"\"\n    if not dados:\n        return []\n    \n    print(\"ğŸ”„ Preparando dados para CSV...\")\n    \n    # Campos que queremos no CSV (ordem especÃ­fica)\n    campos_csv = [\n        'id_item',\n        'titulo', \n        'data_publicacao',\n        'data_formatada',\n        'categoria',\n        'link',\n        'descricao',\n        'guid',\n        'tamanho_titulo',\n        'tamanho_descricao',\n        'link_valido',\n        'timestamp_extracao'\n    ]\n    \n    dados_csv = []\n    \n    for item in dados:\n        item_csv = {}\n        \n        # Copiar apenas campos necessÃ¡rios\n        for campo in campos_csv:\n            valor = item.get(campo)\n            \n            # Tratar valores None\n            if valor is None:\n                item_csv[campo] = \"\"\n            # Converter booleanos para texto\n            elif isinstance(valor, bool):\n                item_csv[campo] = \"Sim\" if valor else \"NÃ£o\"\n            # Garantir que Ã© string\n            else:\n                item_csv[campo] = str(valor)\n        \n        dados_csv.append(item_csv)\n    \n    print(f\"âœ… Dados preparados! {len(dados_csv)} registros prontos para CSV\")\n    print(f\"ğŸ“‹ Campos incluÃ­dos: {len(campos_csv)}\")\n    \n    return dados_csv, campos_csv\n\ndef salvar_dados_json_intermediario(dados, campos):\n    \"\"\"\n    Salva os dados em JSON como backup intermediÃ¡rio\n    \"\"\"\n    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n    nome_arquivo = f\"dados_extraidos_{timestamp}.json\"\n    caminho = output_dir / nome_arquivo\n    \n    try:\n        dados_para_salvar = {\n            'metadados': {\n                'total_registros': len(dados),\n                'campos_incluidos': campos,\n                'timestamp_extracao': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n                'fonte': 'Notebook 3 - Parsing de Tags'\n            },\n            'dados': dados\n        }\n        \n        with open(caminho, 'w', encoding='utf-8') as arquivo:\n            json.dump(dados_para_salvar, arquivo, ensure_ascii=False, indent=2)\n        \n        print(f\"ğŸ’¾ Backup JSON salvo: {nome_arquivo}\")\n        print(f\"ğŸ“ Tamanho: {caminho.stat().st_size:,} bytes\")\n        return str(caminho)\n        \n    except Exception as e:\n        print(f\"âŒ Erro ao salvar JSON: {e}\")\n        return None\n\n# Preparar dados para CSV\nif dados_limpos:\n    dados_csv, campos_csv = preparar_dados_para_csv(dados_limpos)\n    \n    # Salvar backup JSON\n    arquivo_json = salvar_dados_json_intermediario(dados_csv, campos_csv)\nelse:\n    dados_csv, campos_csv = [], []\n    print(\"âš ï¸ Nenhum dado para preparar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ 9. Resumo e PreparaÃ§Ã£o para o Notebook 4\n",
    "\n",
    "Vamos fazer um resumo completo e preparar tudo para o prÃ³ximo notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ‰ RESUMO COMPLETO DO NOTEBOOK 3\")\nprint(\"=\" * 50)\n\nprint(\"âœ… TAREFAS REALIZADAS:\")\nprint(\"   ğŸ› ï¸ ConfiguraÃ§Ã£o do parser XML profissional\")\nprint(\"   ğŸ” Parsing do RSS e extraÃ§Ã£o de elementos\")\nprint(\"   ğŸ“‹ EstruturaÃ§Ã£o de dados de cada notÃ­cia\")\nprint(\"   ğŸ§¹ Limpeza e formataÃ§Ã£o de informaÃ§Ãµes\")\nprint(\"   ğŸ“Š AnÃ¡lise dos dados extraÃ­dos\")\nprint(\"   ğŸ’¾ PreparaÃ§Ã£o dos dados para CSV\")\n\nif dados_csv:\n    print(f\"\\nğŸ“Š ESTATÃSTICAS FINAIS:\")\n    print(f\"   ğŸ—ï¸ NotÃ­cias processadas: {len(dados_csv)}\")\n    print(f\"   ğŸ“‹ Campos estruturados: {len(campos_csv)}\")\n    \n    if estats_dados:\n        print(f\"   ğŸ“‚ Categorias Ãºnicas: {len(estats_dados['categorias'])}\")\n        print(f\"   ğŸ”— Links vÃ¡lidos: {estats_dados['links_validos']}\")\n    \n    print(f\"\\nğŸ“‹ CAMPOS PREPARADOS PARA CSV:\")\n    for i, campo in enumerate(campos_csv, 1):\n        print(f\"   {i:2d}. {campo}\")\nelse:\n    print(\"\\nâš ï¸ Nenhum dado foi processado com sucesso\")\n\nprint(\"\\nğŸ“ ARQUIVOS GERADOS:\")\nif arquivo_json:\n    print(f\"   ğŸ“„ {Path(arquivo_json).name} - Dados estruturados em JSON\")\nelse:\n    print(\"   âŒ Nenhum arquivo gerado\")\n\nprint(\"\\nğŸ“š O QUE APRENDEMOS:\")\nprint(\"   ğŸ”§ Como usar xml.etree.ElementTree para parsing\")\nprint(\"   ğŸ§¹ Como limpar e formatar dados extraÃ­dos\")\nprint(\"   ğŸ“Š Como analisar qualidade dos dados\")\nprint(\"   ğŸ—ï¸ Como estruturar dados para exportaÃ§Ã£o\")\nprint(\"   ğŸ’¾ Como criar backups intermediÃ¡rios\")\n\nprint(\"\\nğŸ¯ DADOS PRONTOS PARA O NOTEBOOK 4:\")\nprint(\"   ğŸ“Š Dados estruturados e limpos\")\nprint(\"   ğŸ“‹ Campos organizados para CSV\")\nprint(\"   âœ… ValidaÃ§Ã£o de qualidade concluÃ­da\")\nprint(\"   ğŸ’¾ Backup de seguranÃ§a criado\")\n\nprint(\"\\n\" + \"=\" * 50)\nif dados_csv:\n    print(\"ğŸš€ Pronto para o Notebook 4 - CriaÃ§Ã£o do CSV!\")\n    print(f\"ğŸ’¡ {len(dados_csv)} registros aguardando conversÃ£o para CSV\")\nelse:\n    print(\"âš ï¸ Verifique os erros acima antes de prosseguir\")\n    \nprint(f\"ğŸ• Notebook 3 concluÃ­do em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
},
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ 1. ConfiguraÃ§Ã£o e ImportaÃ§Ãµes\n",
    "\n",
    "Vamos importar as bibliotecas necessÃ¡rias, incluindo o parser XML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImportaÃ§Ãµes necessÃ¡rias\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "import re\n",
    "import html\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "print(\"âœ… Bibliotecas importadas!\")\n",
    "print(f\"ğŸ• Notebook 3 iniciado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"ğŸ”§ Parser XML: xml.etree.ElementTree\")\n",
    "\n",
    "# Criar diretÃ³rio para outputs\n",
    "output_dir = Path(\"notebook_outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "print(f\"ğŸ“ DiretÃ³rio de saÃ­da: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸŒ 2. Capturando o ConteÃºdo RSS\n",
    "\n",
    "Vamos reutilizar nossa funÃ§Ã£o de requisiÃ§Ã£o dos notebooks anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capturar_rss(url):\n",
    "    \"\"\"\n",
    "    Captura conteÃºdo RSS - funÃ§Ã£o consolidada dos notebooks anteriores\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Accept': 'application/rss+xml, application/xml, text/xml',\n",
    "        'Accept-Language': 'pt-BR,pt;q=0.9,en;q=0.8'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(f\"ğŸ”„ Capturando RSS de: {url}\")\n",
    "        \n",
    "        response = requests.get(url, headers=headers, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        print(f\"âœ… RSS capturado! Tamanho: {len(response.text):,} caracteres\")\n",
    "        return response.text\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"âŒ Erro ao capturar RSS: {e}\")\n",
    "        return None\n",
    "\n",
    "# URL do G1 RSS Brasil\n",
    "url_rss = \"https://g1.globo.com/rss/g1/brasil/\"\n",
    "\n",
    "# Capturar conteÃºdo\n",
    "conteudo_rss = capturar_rss(url_rss)\n",
    "\n",
    "if not conteudo_rss:\n",
    "    print(\"âŒ NÃ£o foi possÃ­vel continuar sem o conteÃºdo RSS\")\n",
    "else:\n",
    "    print(f\"ğŸ“Š Pronto para parsing! ConteÃºdo: {len(conteudo_rss):,} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” 3. Parser XML Profissional\n",
    "\n",
    "Vamos criar um parser XML robusto para extrair dados estruturados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsear_rss_xml(conteudo_xml):\n",
    "    \"\"\"\n",
    "    Parser XML profissional para RSS\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (sucesso, root_element, items_list, info_parsing)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"ğŸ”„ Iniciando parsing XML...\")\n",
    "        \n",
    "        # Fazer parsing do XML\n",
    "        root = ET.fromstring(conteudo_xml)\n",
    "        \n",
    "        # Buscar elementos items\n",
    "        items = root.findall('.//item')\n",
    "        \n",
    "        # InformaÃ§Ãµes do parsing\n",
    "        info_parsing = {\n",
    "            'root_tag': root.tag,\n",
    "            'total_items': len(items),\n",
    "            'namespaces': list(set([elem.tag.split('}')[0].strip('{') for elem in root.iter() if '}' in elem.tag])),\n",
    "            'parsing_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "        \n",
    "        print(f\"âœ… Parsing concluÃ­do!\")\n",
    "        print(f\"ğŸ“Š Items encontrados: {len(items)}\")\n",
    "        print(f\"ğŸ·ï¸ Root tag: {root.tag}\")\n",
    "        \n",
    "        return True, root, items, info_parsing\n",
    "        \n",
    "    except ET.ParseError as e:\n",
    "        print(f\"âŒ Erro de parsing XML: {e}\")\n",
    "        return False, None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erro inesperado: {e}\")\n",
    "        return False, None, None, None\n",
    "\n",
    "# Executar parsing\n",
    "sucesso_parsing, root_xml, items_xml, info_parsing = parsear_rss_xml(conteudo_rss)\n",
    "\n",
    "if not sucesso_parsing:\n",
    "    print(\"âŒ Falha no parsing XML. NÃ£o Ã© possÃ­vel continuar.\")\n",
    "else:\n",
    "    print(\"\\nğŸ“‹ INFORMAÃ‡Ã•ES DO PARSING:\")\n",
    "    for key, value in info_parsing.items():\n",
    "        print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ 4. ExtraÃ§Ã£o Estruturada de Dados\n",
    "\n",
    "Vamos extrair dados de cada item de notÃ­cia de forma estruturada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_dados_item(item_xml, indice):\n",
    "    \"\"\"\n",
    "    Extrai dados estruturados de um item XML\n",
    "    \n",
    "    Args:\n",
    "        item_xml: Elemento XML do item\n",
    "        indice: Ãndice do item na lista\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dados estruturados do item\n",
    "    \"\"\"\n",
    "    dados = {\n",
    "        'id_item': indice,\n",
    "        'timestamp_extracao': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    \n",
    "    # Elementos bÃ¡sicos do RSS\n",
    "    elementos_basicos = {\n",
    "        'titulo': 'title',\n",
    "        'link': 'link', \n",
    "        'descricao': 'description',
        'data_publicacao': 'pubDate',
        'categoria': 'category',
        'guid': 'guid'
    }
    
    # Extrair elementos bÃ¡sicos
    for campo_dados, tag_xml in elementos_basicos.items():
        elemento = item_xml.find(tag_xml)
        if elemento is not None and elemento.text:
            dados[campo_dados] = elemento.text.strip()
        else:
            dados[campo_dados] = None
    
    # Processamento especial para GUID (pode ter atributos)
    guid_elem = item_xml.find('guid')
    if guid_elem is not None:
        dados['guid'] = guid_elem.text.strip() if guid_elem.text else None
        dados['guid_permalink'] = guid_elem.get('isPermaLink', 'false')
    
    # Buscar elementos adicionais (namespaces)
    elementos_extras = item_xml.findall('.//*')
    dados['elementos_encontrados'] = [elem.tag for elem in elementos_extras]
    dados['total_elementos'] = len(elementos_extras)
    
    return dados

def processar_todos_items(items_xml):
    \"\"\"\n    Processa todos os items XML e extrai dados estruturados
    \"\"\"\n    print(f\"ğŸ”„ Processando {len(items_xml)} items...\")\n    \n    dados_extraidos = []\n    \n    for i, item in enumerate(items_xml, 1):\n        print(f\"   ğŸ“‹ Processando item {i}/{len(items_xml)}\", end=\"\\r\")\n        \n        dados_item = extrair_dados_item(item, i)\n        dados_extraidos.append(dados_item)\n    \n    print(f\"\\nâœ… Processamento concluÃ­do! {len(dados_extraidos)} items processados\")\n    return dados_extraidos

# Processar todos os items
if sucesso_parsing:\n    dados_noticias = processar_todos_items(items_xml)\nelse:\n    dados_noticias = []